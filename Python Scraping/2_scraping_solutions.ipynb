{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping WWW Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine front page of BILD newspaper (www.bild.de) and create a list of all articles that can be found on that page. Each item of the list must contain\n",
    "\n",
    "* article title,\n",
    "* main image of the article,\n",
    "* url of the article.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "* request content of `www.bild.de` page and use `\"rel\": \"bookmark\"` properties for identifying links pointing at artiles,\n",
    "* request the content of each article for obtaining the url, the title, the teaser and main image of the article,\n",
    "* you can use `\"og\"` properties of `meta` tag whithin an article to retrieve its title, main image and url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "url = 'http://www.bild.de'\n",
    "# read the website\n",
    "front_page = requests.get(url).text\n",
    "# parse html code\n",
    "front_page_bs_tree = bs4.BeautifulSoup(front_page, 'html.parser')\n",
    "\n",
    "article_link_tags = \\\n",
    "    front_page_bs_tree.find_all(name=\"a\", attrs={'rel': 'bookmark'})\n",
    "\n",
    "\n",
    "base_url = 'http://www.bild.de'\n",
    "\n",
    "article_links = map(lambda tag: tag.get('href'), article_link_tags)\n",
    "article_links = filter(lambda link: 'bild.html' in link, article_links)\n",
    "article_links = map(lambda link: base_url + link, article_links)\n",
    "\n",
    "\n",
    "articles = []\n",
    "\n",
    "for link in list(article_links):\n",
    "    try:\n",
    "        article = requests.get(link).text\n",
    "        article_bs_tree = bs4.BeautifulSoup(article, 'html.parser')\n",
    "        title = \\\n",
    "            article_bs_tree.find(name='meta', \n",
    "                                 attrs={'property': 'og:title'}).get('content')\n",
    "        image = \\\n",
    "            article_bs_tree.find(name='meta', \n",
    "                                 attrs={'property': 'og:image'}).get('content')\n",
    "        url = \\\n",
    "            article_bs_tree.find(name='link', \n",
    "                                 attrs={'rel': 'canonical'}).get('href')\n",
    "        article = {\n",
    "                'title': title,\n",
    "                'image': image,\n",
    "                'url': url}\n",
    "        articles.append(article)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Böller-Bastler sprengte sich sprengte in die Luft. Nachbarin: „Wie bei einer Atombombe“', 'image': 'https://bilder.bild.de/fotos/boeller-bastler-sprengte-sich-sprengte-in-die-luft-nachbarin-wie-bei-einer-atombombe-1dadc6985d524ab094a027020ead7d0b-74672334/Bild/4.bild.jpg', 'url': 'https://www.bild.de/news/inland/news-inland/boeller-bastler-sprengte-sich-sprengte-in-die-luft-nachbarin-wie-bei-einer-atomb-74672320.bild.html'}, {'title': 'Corona: Spahn hält Restaurant- und Konzertbesuche nur für Geimpfte für „möglich“', 'image': 'https://bilder.bild.de/fotos/corona-spahn-haelt-restaurant--und-konzertbesuche-nur-fuer-geimpfte-fuer-moeglich-357cfc6b45054fa396c3aa44d69c2e0a-74671016/Bild/8.bild.jpg', 'url': 'https://www.bild.de/politik/inland/politik-inland/corona-spahn-haelt-restaurant-und-konzertbesuche-nur-fuer-geimpfte-fuer-moeglich-74670998.bild.html'}]\n"
     ]
    }
   ],
   "source": [
    "print(articles[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape International Movies Database (IMDB) at [imdb.com](https://imdb.com) for top 1000 films released in year 2018 with the highest US box office. The result must me a list containing 1000 elements, where each element is a ditionary with elements \n",
    "\n",
    "* `name` - title of the movie, \n",
    "* `year` - release year of the movie, \n",
    "* `imdb` - IMDB score of the movie, \n",
    "* `m_score` - meta score of the movie, \n",
    "* `vote` - number of votes.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "* use `https://www.imdb.com/search/title?release_date=2018&sort=boxoffice_gross_us,desc&start=1` to get first top 50 movies; by setting `start` to `51`, `101`, etc. navigate through the movies list,\n",
    "* you may want to use `sleep(randint(0,10))` from `time` module to introduce a delay between the request in order to avoid being temporary banned for scraping the content,\n",
    "* use developer tools for identifying `<div>` containers containing information about movies,\n",
    "* release of a movie may be presented as `(2018)`, `(I) (2018)`, `(II) (2018)` etc.; use `int(year[-5:-1])` for converting it into integer.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "# Redeclaring the lists to store data in\n",
    "films = []\n",
    "\n",
    "pages = range(20)\n",
    "starts = map(lambda x: str(10*x+1), pages)\n",
    "\n",
    "for start in starts:\n",
    "\n",
    "    # Make a get request\n",
    "    response = get('http://www.imdb.com/search/title?release_date=2018' + \n",
    "    '&sort=boxoffice_gross_us,desc&start=' + start)\n",
    "\n",
    "    # Pause the loop\n",
    "    sleep(randint(0,10))\n",
    "\n",
    "    # Throw a warning for non-200 status codes\n",
    "    if response.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Select all the 50 movie containers from a single page\n",
    "    mv_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "\n",
    "    # For every movie of these 50\n",
    "    for container in mv_containers:\n",
    "        # If the movie has a Metascore, then:\n",
    "        if container.find('div', class_ = 'ratings-metascore') is not None:\n",
    "\n",
    "            film = {}\n",
    "            # Scrape the name\n",
    "            film['name'] = container.h3.a.text\n",
    "\n",
    "            # Scrape the year \n",
    "            film['year'] = int(container.h3.find('span', class_ = 'lister-item-year').text[-5:-1])\n",
    "\n",
    "            # Scrape the IMDB rating\n",
    "            film['imdb'] = float(container.strong.text)\n",
    "\n",
    "            # Scrape the Metascore\n",
    "            film['m_score'] = int(container.find('span', class_ = 'metascore').text)\n",
    "\n",
    "            # Scrape the number of votes\n",
    "            film['vote'] = int(container.find('span', attrs = {'name':'nv'})['data-value'])\n",
    "\n",
    "            films.append(film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Black Panther', 'year': 2018, 'imdb': 7.3, 'm_score': 88, 'vote': 550835}, {'name': 'Avengers: Infinity War', 'year': 2018, 'imdb': 8.5, 'm_score': 68, 'vote': 724440}, {'name': 'Die Unglaublichen 2', 'year': 2018, 'imdb': 7.7, 'm_score': 80, 'vote': 218935}, {'name': 'Jurassic World: Das gefallene Königreich', 'year': 2018, 'imdb': 6.2, 'm_score': 51, 'vote': 233041}, {'name': 'Aquaman', 'year': 2018, 'imdb': 7.0, 'm_score': 55, 'vote': 310821}, {'name': 'Deadpool 2', 'year': 2018, 'imdb': 7.7, 'm_score': 66, 'vote': 424203}, {'name': 'Der Grinch', 'year': 2018, 'imdb': 6.3, 'm_score': 51, 'vote': 33973}, {'name': 'Mission: Impossible - Fallout', 'year': 2018, 'imdb': 7.8, 'm_score': 86, 'vote': 251754}, {'name': 'Ant-Man and the Wasp', 'year': 2018, 'imdb': 7.1, 'm_score': 70, 'vote': 266470}, {'name': 'Bohemian Rhapsody', 'year': 2018, 'imdb': 8.0, 'm_score': 49, 'vote': 392113}]\n"
     ]
    }
   ],
   "source": [
    "print(films[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
